{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tll9ofc41bc7f0uchagxnm"
   },
   "source": [
    "# Задача распознавания говорящего по голосу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ouwakt5asjvaowvc6qahe"
   },
   "source": [
    "## I. Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "h33nxhqk056r5agev40cz9"
   },
   "source": [
    "На основании имеющихся данных мы хотим научиться определять говорящего. **Data-set** представляет собой два набора данных:\n",
    "\n",
    "1. Trainig corpus. Голосовые высказывания спикеров (несколько записей по каждому спикеру).\n",
    "2. Test corpus. Другие записи тех же спикеров.\n",
    "\n",
    "Все аудиофайлы имеют длительность 10 секунд и сэмплируются на частоте 16000 Гц."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3qgydy9hkb5gbr1cn7b35g"
   },
   "source": [
    "## II. Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "x86k14nyl4sqty8uqvqdof"
   },
   "source": [
    "Речевой сигнал представляет собой последовательность чисел, которые определяют амплитуду говорящего. Вся концепция распознавания речи базируется на трёх основных принципах/инструментах:\n",
    "\n",
    "* Framing\n",
    "* Windowing\n",
    "* Overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4176ljwxii4hirtfcpy99e"
   },
   "source": [
    "### 1. Framing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "l9jaf7129g79lfoywc22cq"
   },
   "source": [
    "Поскольку речь не является стационарным сигналом (стационарностью называется свойство процесса сохранять свои характеристики с течением времени), её частотное содержание постоянно изменяется во времени. Чтобы выполнить хоть какой-нибудь анализ сигнала на коротких временных интервалах (*Short Term Fourier Transformation*), нам надо иметь возможность рассмотреть сигнал как стационарный. Чтобы достичь этой стационарности, речевой сигнал делится на ***фреймы*** длинной 20-30 мс. На такой длине можно сделать предположение о том, что форма волны не изменяется или изменяется совсем незначительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qp8rqs3yauf5uxmkli764"
   },
   "source": [
    "![frame-segmentation](presentation/Segmentation-of-speech-signals-frame-by-frame.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vxf2fiflkuflvc13aj2ga"
   },
   "source": [
    "### 2. Windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "28sl781qjhzfwxd9xvjdih"
   },
   "source": [
    "Извлечение фреймов из речевого сигнала может привести к разрывам в целых точках из-за нецелого числа периодов в извлечённом сигнале, что в свою очередь может привести к ошибочному представлению частоты, так называемой _спектральной утечке_ — _spectral leakage_. Это можно предотвратить умножением фрейма на некоторую ***оконную функцию***. Амплитуда оконной функции падает до нуля на концах фрейма, что естественным образом минимизирует амплитуду разрыва."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ehdx8pxhuy581lbvm2tqxg"
   },
   "source": [
    "На картинках ниже приведена иллюстрация фрейма до и после умножения на оконную функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "24o5kqlbnrpg42gxlhevrg7"
   },
   "source": [
    "![non-integer](presentation/noninteger1.png) ![windowing](presentation/window2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "bocap5skzajdbr5niyhxer"
   },
   "source": [
    "### 3. Overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "obodxfc65fzhsfzrbyq6"
   },
   "source": [
    "Из-за windowing'а возможна ситуация, когда в результате «сужения» мы теряем часть информации о сигнале на концах фрейма. Чтобы нивелировать этот возможный дефект, необходимо сделать ***перекрытие*** фреймов. Суть его в следующем: пусть фрейм *s* имеет длину 20-30 мс. Возьмём фрейм *s+1*, который также имеет длину 20-30 ms и «наложим» его частично на фрейм *i*. Длина перекрытия обычно равна 10-15 мс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7em8vm2qwkpi51tj08ehmh"
   },
   "source": [
    "Поясняющая иллюстрация:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "l6gvf11j5s8jxh2bp8beb"
   },
   "source": [
    "![overlapping](presentation/mfcc_audioframes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "08oqlpppbhtw8s9s08t57m6"
   },
   "source": [
    "## III. Gaussian Mixture Model (GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ey4mv4w0tcedw0eiugk1b"
   },
   "source": [
    "**Gaussian Mixture Model (GMM)** — вероятностная модель кластеризации для представления присутствия под-популяции в охватывающей популяции. Идея обучения GMM — приблизить распределение вероятности класса линейной комбинацией $k$ гауссовых распределений, которые также называются компонентами GMM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "wyliqedwfsesesr84dpk"
   },
   "source": [
    "Вероятность точек данных (векторов признака) для модели задаётся следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "nupxl42vkkep6ea72eso2i"
   },
   "source": [
    "$\\mathbf{P} (\\mathbf{x} \\vert \\lambda) = \\sum_{k = 1}^{K} \\omega_k f_{\\mathbf{X}_k}(\\mathbf{x})$, где"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "30v9zelnbql38624of9mz"
   },
   "source": [
    "$f_{\\mathbf{X}}(\\mathbf{x}) = \\frac{1}{(2\\pi )^{n/2} \\vert \\Sigma \\vert^{1/2}} e^{-\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu})^{\\top} \\Sigma^{-1} (\\mathbf{x} - \\mathbf{\\mu})},\\; \\mathbf{x} \\in \\mathbb{R}^n$, \n",
    "\n",
    "где $\\vert \\Sigma\\vert$ — определитель матрицы $\\Sigma$, а $\\Sigma^{-1}$ — матрица, обратная к $\\Sigma$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xkudscbocf44a4q5fubmr"
   },
   "source": [
    "Training data $X_i$ класса $\\lambda$ используется для оценки значений всех параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "lwcxro34pr4vekucnlf7g"
   },
   "source": [
    "Вначале определяется $k$ классв в данных $K$-средним алгоритмом с весами $\\omega = 1/k$ для каждого кластера. Затем $k$ гауссовых распределений фитят $k$ кластеров, все параметры при этом обновляются итеративно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "onc2mbh3vuy9wadibl5r"
   },
   "source": [
    "## IV. Демонстрация решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "435wj1zq66s4umyt6o5se3"
   },
   "source": [
    "### Установка и импорт необходимых пакетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tz8jup8rqxf00gno8y6tg"
   },
   "outputs": [],
   "source": [
    "%pip install numba==0.48.0\n",
    "%pip install librosa\n",
    "%pip install cffi==1.14.2\n",
    "%pip show numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После установки перезапустите ядро, выбрав в главном меню **Kernel** → **Restart kernel**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hxe1msiec5fztvibbp8y8f"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import librosa\n",
    "from librosa import display\n",
    "from IPython.display import Audio \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "58sjsz6c7u8wpm7arf1mia"
   },
   "source": [
    "### Генерация аудио-признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "lpwude9n8od1c61dun5cu9"
   },
   "source": [
    "Создадим функцию, которая будет извлекать аудио-признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ay7n7dmrl1tbi4y68osks4"
   },
   "outputs": [],
   "source": [
    "def audio_features_extraction(sample, sample_rate, n_fft):\n",
    "    \n",
    "    \"\"\" \n",
    "        sample - audio time series\n",
    "        sample_rate - sampling rate of sample\n",
    "        n_fft = frame size\n",
    "    \"\"\"\n",
    "    \n",
    "    # librosa.feature.mfcc – вычисляет коэффициенты MFCCs.\n",
    "    # MFCCs трансформируют значение сигнала в кепстр – один из видов гомоморфной обработки сигналов, \n",
    "    # функция обратного преобразования Фурье от логарифма спектра мощности сигнала. \n",
    "    # Основная задача: охарактеризовать фильтр и отделить исходную часть\n",
    "    # (на примере с голосом человека – охарактеризовать вокальный тракт).\n",
    "    mfcc = librosa.feature.mfcc(y=sample, \n",
    "                                n_fft=n_fft, # размер фрейма\n",
    "                                window='hann',  # оконная функция (windowing)\n",
    "                                hop_length=int(n_fft*0.5), # размер перекрытия фреймов (overlapping)\n",
    "                                sr=sample_rate, \n",
    "                                n_mfcc=20)\n",
    "    features = np.mean(mfcc, axis=1)\n",
    "    \n",
    "    # librosa.feature.zero_crossing находит нулевые переходы для сигнала.\n",
    "    zero_crossings = sum(librosa.zero_crossings(sample, pad=False))\n",
    "    features = np.append(zero_crossings, features)\n",
    "    \n",
    "    # librosa.feature.spectral_centroid вычисляет спектральный центроид.\n",
    "    # Каждый фрейм амплитудной спектрограммы нормализуется и обрабатывается как распределение по частотным элементам,\n",
    "    # из которого извлекается среднее значение (центроид) для каждого фрейма.\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=sample,n_fft=n_fft, hop_length=int(n_fft*0.5), window='hann', sr=sample_rate).mean()\n",
    "    features = np.append(spec_cent, features)\n",
    "    \n",
    "    # librosa.feature.spectral_flatness вычисляет cпектральную плоскостность.\n",
    "    # Спектральная плоскостность - количественная мера того, насколько звук похож на шум, а не на тон.\n",
    "    spec_flat = librosa.feature.spectral_flatness(y=sample,n_fft=n_fft, hop_length=int(n_fft*0.5), window='hann').mean()\n",
    "    features = np.append(spec_flat, features)\n",
    "    \n",
    "    # librosa.feature.spectral_bandwith вычисляет спектральную полосу пропускания p-ого порядка.\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=sample,n_fft=n_fft, hop_length=int(n_fft*0.5), window='hann', sr=sample_rate).mean()\n",
    "    features = np.append(spec_bw, features)\n",
    "    \n",
    "    # librosa.feature.spectral_rolloff вычисляет roll-off частоту для каждого фрейма.\n",
    "    # Roll-off частота определяется как центральная частота для интервала спектрограммы.\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=sample, n_fft=n_fft, hop_length=int(n_fft*0.5), window='hann', sr=sample_rate).mean()\n",
    "    features = np.append(rolloff, features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u4awkxs4b43ixoavmci03"
   },
   "source": [
    "Читаем последовательно аудио-файлы и извлекаем аудио-признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "yoicsxqstrd9xvvpxg7ajk"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "source   = \"./data/development_set/\"  \n",
    "dest = \"./data/speaker-models/\"\n",
    "train_file = \"./data/development_set_enroll.txt\"\n",
    "file_paths = open(train_file, 'r')\n",
    " \n",
    "n_fft = 1024\n",
    "\n",
    "# Подготовка датасетов для обучения моделей.\n",
    "features = pd.DataFrame()\n",
    "speakers = pd.DataFrame()\n",
    "\n",
    "# Последовательное чтение аудио-файлов из тренировочного семпла.\n",
    "for path in tqdm(file_paths, desc='Features extractions '):\n",
    "    path = path.replace(\"\\\\\",\"/\").strip()\n",
    "    speaker = path.split(\"-\",1)[0]\n",
    "\n",
    "    # librosa.load - загрузка аудио-файла.\n",
    "    sample, sample_rate = librosa.load(source+path)\n",
    "    \n",
    "    # Извлечение аудио-признаков.\n",
    "    features = features.append(pd.Series(audio_features_extraction(sample, sample_rate, n_fft)), ignore_index=True) \n",
    "    speakers = speakers.append({'speaker' : speaker}, ignore_index=True)\n",
    " \n",
    "print('Execution time: ', round((time.time() - start),2))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tgq0it0wvjc18c8hqbwwwa"
   },
   "source": [
    "Нормируем признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "s9yseie4829a8fnuy3fnf"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features_scaled = pd.DataFrame(scaler.transform(features))\n",
    "pickle.dump(scaler, open('scaler','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "5sgff9ktpfw11k3nx5s2l"
   },
   "source": [
    "### Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ip5mke42jaz2vtjtvpbs"
   },
   "source": [
    "Обучаем модели и сохраняем в директорию `./data/speaker-models/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "scidkmetempbwvwfhxfr"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "features_smpl = pd.DataFrame()\n",
    "count = 1\n",
    "\n",
    "if not os.path.exists(os.path.dirname(dest)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(dest))\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "for i in range(speakers.shape[0]):\n",
    "    speaker = speakers.iloc[i:i+1].values[0]\n",
    "    if count == 1:\n",
    "        speaker_prev = speaker     \n",
    "    else :\n",
    "        # Обучение модели GaussianMixture для каждого спикера\n",
    "        if (speaker_prev != speaker) | (i == len(speakers)-1) :\n",
    "            gmm = GaussianMixture(n_components = min(16, features_smpl.shape[0]), \n",
    "                                  max_iter = 200, covariance_type='diag', n_init = 3)\n",
    "            gmm.fit(features_smpl)\n",
    "            \n",
    "            # Сохранение полученной модели в pickle\n",
    "            pickle.dump(gmm, open((dest+speaker_prev)[0],'wb'))\n",
    "            features_smpl = pd.DataFrame()\n",
    "            count = 0\n",
    "            speaker_prev = speaker\n",
    "            \n",
    "    # Сбор данных по одному спикеру.\n",
    "    features_smpl  = features_smpl.append(features_scaled.iloc[i:i+1], ignore_index=True)\n",
    "    count = count+1\n",
    "\n",
    "print('Execution time: ', round((time.time() - start),2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "pdej0sspb28cctnvi2nmcv"
   },
   "source": [
    "### Тестирование на тестовом семпле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "fj8md7md185qnnvgxe5pqo"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "source     = \"./data/development_set/\"  \n",
    "dest       = \"./data/speaker-models/\"\n",
    "test_file  = \"./data/development_set_test.txt\"\n",
    "file_paths = open(test_file,'r')\n",
    " \n",
    "n_fft = 1024\n",
    "\n",
    "features = pd.DataFrame()\n",
    "result   = pd.DataFrame()\n",
    "\n",
    "gmm_files = [os.path.join(dest,fname) for fname in os.listdir(dest)]\n",
    "gmm_files = [fname for fname in gmm_files if not '.ipynb' in fname]\n",
    "models    = [pickle.load(open(fname,'rb')) for fname in gmm_files ]\n",
    "scaler    = pickle.load(open('scaler','rb'))\n",
    "\n",
    "# Последовательное чтение аудио-файлов из тестового семпла.\n",
    "for path in tqdm(file_paths, desc='Score test sample '):\n",
    "    \n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    path = path.replace(\"\\\\\",\"/\").strip()\n",
    "    speaker = path.split(\"-\",1)[0]\n",
    "    \n",
    "    # librosa.load - загрузка аудио-файла.\n",
    "    sample, sample_rate = librosa.load(source+path)\n",
    "    \n",
    "    # Извлечение аудио-признаков.\n",
    "    features = features.append(pd.Series(audio_features_extraction(sample, sample_rate, n_fft)), ignore_index=True) \n",
    "\n",
    "    # Нормирование аудио-признаков.\n",
    "    features = scaler.transform(features)\n",
    "    \n",
    "    # Скоринг каждой моделью\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i] \n",
    "        scores = np.array(gmm.score(features))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "        \n",
    "    # Выбор спикера по наибольшему скору\n",
    "    winner = np.argmax(log_likelihood)\n",
    "    result = result.append({'speaker' : speaker,\n",
    "                           'winner' : gmm_files[winner].split(\"/\",3)[-1]}, ignore_index=True)\n",
    "    \n",
    "print('Execution time: ', round((time.time() - start),2))   \n",
    "print('Точность угадывания, %: ', round(100*result[result['speaker']==result['winner']].shape[0]/result.shape[0],2))\n",
    "# Во время работы ячейки могут появляться предупреждения о невозможности сериализации переменных\n",
    "# Все переменные, что указаны в этих предупреждениях будут доступны только на той конфигурации ячеек, на которой была запущенна данная"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notebookId": "44ad9ac3-5310-4ead-a8d2-b022f73443f9"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
